"""
ì¤‘ì¬ì ì—ì´ì „íŠ¸: ì—ì´ì „íŠ¸ ê·¸ë£¹ì˜ í–‰ë™ì„ ì¡°ìœ¨í•˜ëŠ” ìƒìœ„ ì •ì±….

Genesis v2.0 Strategy B: Leviathan Update
í—Œë²• ì œ12ì¡° 1í•­ ì´ë¡ ì  ê·¼ê±°:
  - Ivanov et al. (2023) "Mediated Multi-Agent Reinforcement Learning"
  - Hobbes, Leviathan (1651) â€” ì‚¬íšŒê³„ì•½ë¡ 

ë™ì‘ ë°©ì‹:
1. k ìŠ¤í…ë§ˆë‹¤ ì—ì´ì „íŠ¸ì—ê²Œ ìœ„ì„ ì—¬ë¶€ë¥¼ ë¬»ëŠ”ë‹¤.
2. ìœ„ì„í•œ ì—ì´ì „íŠ¸ì˜ í–‰ë™ì„ ì‚¬íšŒì  ë³µì§€ ê·¹ëŒ€í™”ë¡œ ëŒ€ì²´.
3. IC ì œì•½: ìœ„ì„ > ë…ë¦½ í–‰ë™ (ê¸°ëŒ€ ë³´ìƒ)
4. E ì œì•½: ë¬´ì„ìŠ¹ì°¨ ë¶ˆì´ìµ ë³´ì¥
"""
import jax
import jax.numpy as jnp
import json
import os
from datetime import datetime


class Mediator:
    """
    ì¤‘ì¬ì ì—ì´ì „íŠ¸.

    ì—ì´ì „íŠ¸ë“¤ì˜ ìœ„ì„ì„ ë°›ì•„ ì§‘ë‹¨ ì´ìµ ìµœëŒ€í™” ì •ì±…ì„ ì‹¤í–‰.
    """

    def __init__(self, config=None):
        config = config or {}
        self.commitment_window = config.get("MEDIATOR_K", 10)
        self.lambda_ic = config.get("MEDIATOR_LAMBDA_IC", 1.0)
        self.lambda_e = config.get("MEDIATOR_LAMBDA_E", 0.5)
        self.delegation_history = []
        self.step_counter = 0

    def should_consult(self):
        """ìœ„ì„ ê²°ì • ì‹œì ì¸ì§€ í™•ì¸ (k ìŠ¤í…ë§ˆë‹¤)."""
        self.step_counter += 1
        return self.step_counter % self.commitment_window == 0

    def check_delegation(self, agent_reward_history, mediator_reward_history):
        """
        ì—ì´ì „íŠ¸ê°€ ìœ„ì„í• ì§€ ê²°ì • (IC ì œì•½ ê¸°ë°˜).

        Args:
            agent_reward_history: ë…ë¦½ í–‰ë™ ì‹œ ë³´ìƒ ì´ë ¥
            mediator_reward_history: ì¤‘ì¬ì ê°€ì´ë“œ ì‹œ ë³´ìƒ ì´ë ¥

        Returns:
            bool: ìœ„ì„ ì—¬ë¶€
        """
        if len(agent_reward_history) < 5 or len(mediator_reward_history) < 5:
            return True  # ì´ˆê¸°ì—ëŠ” ìœ„ì„ ì„ í˜¸ (íƒìƒ‰)

        indep_value = sum(agent_reward_history[-20:]) / min(len(agent_reward_history), 20)
        med_value = sum(mediator_reward_history[-20:]) / min(len(mediator_reward_history), 20)

        delegate = med_value > indep_value
        self.delegation_history.append({
            "step": self.step_counter,
            "indep_value": indep_value,
            "med_value": med_value,
            "delegated": delegate,
        })
        return delegate

    def compute_collective_action(self, n_agents, cooperation_rates=None):
        """
        ìœ„ì„ë°›ì€ ì—ì´ì „íŠ¸ë“¤ì˜ í–‰ë™ì„ ì‚¬íšŒì  ë³µì§€ ê·¹ëŒ€í™”ë¡œ ê²°ì •.

        ì´ˆê¸° ë²„ì „: ì—­í•  ë¶„ë‹´ ê¸°ë°˜ (1/3 ì²­ì†Œ, 2/3 ì±„ì§‘)
        í–¥í›„: í•™ìŠµëœ ì •ì±…ìœ¼ë¡œ ëŒ€ì²´

        Args:
            n_agents: ì—ì´ì „íŠ¸ ìˆ˜
            cooperation_rates: ì—ì´ì „íŠ¸ë³„ í˜„ì¬ í˜‘ë ¥ë¥  [N]

        Returns:
            actions: [N] í–‰ë™ ë²¡í„°
        """
        actions = jnp.zeros(n_agents, dtype=jnp.int32)

        # í˜‘ë ¥ë¥ ì´ ë‚®ì€ ì—ì´ì „íŠ¸ë¥¼ ì²­ì†Œë¡œ ë°°ì •
        if cooperation_rates is not None:
            n_cleaners = max(n_agents // 3, 1)
            # í˜‘ë ¥ë¥ ì´ ê°€ì¥ ë‚®ì€ ì—ì´ì „íŠ¸ë“¤ì„ ì²­ì†Œë¡œ
            worst_agents = jnp.argsort(cooperation_rates)[:n_cleaners]
            actions = actions.at[worst_agents].set(5)  # 5 = CLEAN í–‰ë™ (í™˜ê²½ ì˜ì¡´)
        else:
            # ê¸°ë³¸: ê· ë“± ë¶„ë°°
            n_cleaners = n_agents // 3
            actions = actions.at[:n_cleaners].set(5)

        return actions

    def get_delegation_rate(self):
        """ìœ„ì„ë¥  ê³„ì‚°."""
        if not self.delegation_history:
            return 0.0
        recent = self.delegation_history[-50:]
        return sum(1 for d in recent if d["delegated"]) / len(recent)

    def get_report(self):
        """ì¤‘ì¬ì ìƒíƒœ ë³´ê³ ì„œ."""
        return {
            "total_consultations": len(self.delegation_history),
            "delegation_rate": self.get_delegation_rate(),
            "commitment_window": self.commitment_window,
            "step_counter": self.step_counter,
        }


if __name__ == "__main__":
    print("ğŸ§ª mediator.py ë‹¨ìœ„ í…ŒìŠ¤íŠ¸")
    print("=" * 50)

    med = Mediator({"MEDIATOR_K": 5})

    # ìœ„ì„ ì‹œì  í…ŒìŠ¤íŠ¸
    for i in range(12):
        consult = med.should_consult()
        if consult:
            print(f"  Step {i+1}: ğŸ¤ ìœ„ì„ ê²°ì • ì‹œì !")

    # ìœ„ì„ ê²°ì • í…ŒìŠ¤íŠ¸
    agent_hist = [0.3, 0.2, 0.4, 0.1, 0.3, 0.2]
    med_hist = [0.5, 0.6, 0.4, 0.5, 0.7, 0.6]
    result = med.check_delegation(agent_hist, med_hist)
    print(f"\n  ìœ„ì„ ê²°ì •: {result} (med > indep)")

    # ì§‘ë‹¨ í–‰ë™ í…ŒìŠ¤íŠ¸
    actions = med.compute_collective_action(10)
    print(f"  ì§‘ë‹¨ í–‰ë™ (10ëª…): {actions}")

    print(f"  ìœ„ì„ë¥ : {med.get_delegation_rate():.2%}")
    print(f"\nâœ… ëª¨ë“  í…ŒìŠ¤íŠ¸ í†µê³¼!")
