# EthicaAI: When Should AI Agents Be Moral? ğŸ§ âš–ï¸

[![NeurIPS 2026](https://img.shields.io/badge/Target-NeurIPS_2026-blue?style=for-the-badge&logo=neurips)](https://neurips.cc)
[![30 Figures](https://img.shields.io/badge/Figures-30-brightgreen?style=for-the-badge)](https://ethicaai.vercel.app)
[![560+ Experiments](https://img.shields.io/badge/Experiments-560+-orange?style=for-the-badge)]()
[![Python 3.10+](https://img.shields.io/badge/python-3.10+-blue.svg?style=for-the-badge&logo=python&logoColor=white)](https://www.python.org)
[![JAX](https://img.shields.io/badge/JAX-Accelerated-9cf?style=for-the-badge&logo=google&logoColor=white)](https://github.com/google/jax)
[![License: MIT](https://img.shields.io/badge/License-MIT-yellow.svg?style=for-the-badge)](LICENSE)

> **"The question isn't *whether* AI should be moral, but *when*."**

**EthicaAI** formalizes Amartya Sen's **Meta-Ranking** theory (preferences over preferences) as a dynamic mechanism in Multi-Agent Reinforcement Learning. We demonstrate that _Situational Commitment_ â€” morality conditional on survival â€” is the only Evolutionarily Stable Strategy across 4 environments, 7 SVO conditions, and up to 1,000 agents.

<p align="center">
  <a href="https://ethicaai.vercel.app"><strong>ğŸŒ Interactive Dashboard (30 Figures)</strong></a> &nbsp;|&nbsp;
  <a href="paper_english.md"><strong>ğŸ“„ Full Paper</strong></a> &nbsp;|&nbsp;
  <a href="submission_neurips/main.tex"><strong>ğŸ“ LaTeX</strong></a>
</p>

---

## ğŸ”¬ Five Key Findings

| # | Finding | Evidence |
|:-:|---------|---------|
| **1** | Dynamic meta-ranking (Î»_t) significantly enhances collective welfare | p=0.0003, Cohen's fÂ²=0.40 |
| **2** | Agents exhibit emergent **role specialization** (Cleaners vs Eaters) | Ïƒ divergence p<0.0001 |
| **3** | Only "Situational Commitment" survives as **ESS** (~12% of population) | 200-gen replicator dynamics |
| **4** | Individualist SVO (Î¸=15Â°) best matches **human PGG data** | WD=0.053 |
| **5** | SVO rotation accounts for **86%** of total effect | Full factorial 2Â³ decomposition |

---

## ğŸŒŸ Extended Results (Phase M)

### Full Environmental Sweep (560 runs)
4 environments Ã— 7 SVO Ã— 10 seeds â€” the most comprehensive test of meta-ranking to date.

| Environment | Best ATE (Cooperation) | Optimal SVO | ATE (Reward) |
|:-:|:-:|:-:|:-:|
| Cleanup | +0.083 | Cooperative (60Â°) | â€” |
| **PGG** | **+0.211** | **Prosocial (45Â°)** | **+2.535** |
| **Harvest** | **+0.506** | **Selfish (0Â°)** | **+0.101** |

### Mixed-SVO Populations: Tipping Point
A **nonlinear tipping point** at ~30% prosocial fraction triggers population-wide cooperation. PGG welfare improvement: **Î”W = +10,080**.

### Communication Channels
1-bit cheap talk boosts cooperation by **+5.8%** for prosocial agents. Message truthfulness converges to **98%** â€” honesty is evolutionarily favored.

### Continuous Action Spaces
Beta-distribution policies in continuous PGG maintain meta-ranking's ATE â‰ˆ **+0.20**, confirming generalization beyond discrete decisions.

---

## ğŸ› ï¸ Installation

```bash
# Clone & setup
git clone https://github.com/Yesol-Pilot/EthicaAI.git
cd EthicaAI

python -m venv ethica_env
source ethica_env/bin/activate  # Windows: ethica_env\Scripts\activate
pip install -r requirements.txt
```

**Requirements**: Python 3.10+, CUDA 12+ (optional, for GPU acceleration)

---

## ğŸš€ Quick Start

### Reproduce All Results (One Command)
```bash
# All 11 analysis modules (Phase G + H + M)
python reproduce.py

# Phase M only (4 new experiments)
python reproduce.py --phase M

# Quick demo
python reproduce.py --quick
```

### Run Individual Experiments
```bash
# M1: Full Sweep (4 envs Ã— 7 SVO Ã— 10 seeds)
python -m simulation.jax.analysis.run_full_sweep simulation/outputs/reproduce

# M2: Mixed-SVO tipping point analysis
python -m simulation.jax.analysis.mixed_svo_experiment simulation/outputs/reproduce

# M3: Communication channels (cheap talk)
python -m simulation.jax.analysis.communication_experiment simulation/outputs/reproduce

# M4: Continuous PGG (Beta-distribution policies)
python -m simulation.jax.analysis.continuous_experiment simulation/outputs/reproduce
```

### Full Training Pipeline (100 Agents)
```bash
python -m simulation.jax.run_full_pipeline large_full      # Meta-Ranking ON
python -m simulation.jax.run_full_pipeline large_baseline   # Baseline (OFF)
```

### Prepare arXiv Submission
```bash
python prepare_arxiv.py  # Generates ethicaai_arxiv.tar.gz
```

---

## ğŸ“Š 30 Figures

All figures are interactive at [ethicaai.vercel.app](https://ethicaai.vercel.app).

| Phase | Figures | Content |
|:-----:|:-------:|---------|
| **Core** (Aâ€“D) | Fig 1â€“9 | Learning curves, cooperation rates, role specialization, Gini, causal forest |
| **Scale** (E) | Fig 10â€“11 | 100-agent scale comparison, ATE analysis |
| **Robustness** (G) | Fig 12â€“16 | Convergence, static/dynamic Î», sensitivity, cross-environment |
| **Extended** (H) | Fig 17â€“23 | PGG, evolution, mechanism decomposition, Harvest, Melting Pot, Constitutional AI |
| **Deep** (M) | Fig 24â€“30 | Full sweep heatmap, mixed-SVO tipping point, communication, continuous PGG |

---

## ğŸ“‚ Repository Structure

```
EthicaAI/
â”œâ”€â”€ simulation/
â”‚   â””â”€â”€ jax/
â”‚       â”œâ”€â”€ analysis/              # 11 analysis modules
â”‚       â”‚   â”œâ”€â”€ run_full_sweep.py         # M1: Full environmental sweep
â”‚       â”‚   â”œâ”€â”€ mixed_svo_experiment.py   # M2: Mixed-SVO populations
â”‚       â”‚   â”œâ”€â”€ communication_experiment.py # M3: Cheap talk
â”‚       â”‚   â”œâ”€â”€ continuous_experiment.py  # M4: Continuous PGG
â”‚       â”‚   â”œâ”€â”€ convergence_proof.py      # Convergence verification
â”‚       â”‚   â”œâ”€â”€ sensitivity_analysis.py   # Parameter sensitivity
â”‚       â”‚   â””â”€â”€ ...                       # 5 more modules
â”‚       â”œâ”€â”€ environments/          # Cleanup, IPD, PGG, Harvest
â”‚       â”œâ”€â”€ training/              # MAPPO training pipeline
â”‚       â””â”€â”€ run_full_pipeline.py   # End-to-end execution
â”œâ”€â”€ submission_neurips/            # LaTeX (NeurIPS 2026 format)
â”œâ”€â”€ submission_arxiv/              # arXiv package (32 figures)
â”œâ”€â”€ site/                          # Interactive dashboard (Vercel)
â”œâ”€â”€ reproduce.py                   # One-command reproduction (11 modules)
â”œâ”€â”€ prepare_arxiv.py               # arXiv package generator
â”œâ”€â”€ paper_english.md               # Full paper (English)
â”œâ”€â”€ paper_korean.md                # Full paper (Korean)
â””â”€â”€ twitter_thread_draft.md        # Social media draft
```

---

## ğŸ“ˆ Reproduction Pipeline

```
$ python reproduce.py --phase M
============================================================
  EthicaAI Reproduction Pipeline
  Phase: M  |  Mode: Full
============================================================
  âœ“ M1: Full Sweep (4í™˜ê²½ Ã— 7SVO Ã— 10seeds)     â€” 15.2s
  âœ“ M2: Mixed-SVO Population (ì„ê³„ì  ë¶„ì„)        â€” 10.1s
  âœ“ M3: Communication Channels (Cheap Talk)      â€”  8.3s
  âœ“ M4: Continuous PGG (ì—°ì† í–‰ë™ ê³µê°„)           â€”  6.8s

  Total: 4/4 succeeded (45.4s)
  ğŸ‰ ì „ì²´ ì¬í˜„ ì„±ê³µ!
```

---

## ğŸ“œ Citation

```bibtex
@article{heo2026ethicaai,
  title={Beyond Homo Economicus: Computational Verification of Amartya Sen's
         Meta-Ranking Theory via Multi-Agent Reinforcement Learning},
  author={Heo, Yesol},
  journal={arXiv preprint arXiv:2602.XXXXX},
  year={2026},
  note={30 figures, 560+ experiments, 4 environments, 11 reproduction modules}
}
```

---

## ğŸ“„ License

MIT License. See [LICENSE](LICENSE) for details.

> *Built with â¤ï¸ by the Antigravity Team.*
