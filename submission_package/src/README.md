# EthicaAI: When Should AI Agents Be Moral? ğŸ§ âš–ï¸

[![NeurIPS 2026](https://img.shields.io/badge/Target-NeurIPS_2026-blue?style=for-the-badge&logo=neurips)](https://neurips.cc)
[![74 Figures](https://img.shields.io/badge/Figures-74-brightgreen?style=for-the-badge)](https://ethicaai.vercel.app)
[![38 Modules](https://img.shields.io/badge/Modules-38-orange?style=for-the-badge)]()
[![Python 3.10+](https://img.shields.io/badge/python-3.10+-blue.svg?style=for-the-badge&logo=python&logoColor=white)](https://www.python.org)
[![JAX](https://img.shields.io/badge/JAX-Accelerated-9cf?style=for-the-badge&logo=google&logoColor=white)](https://github.com/google/jax)
[![License: MIT](https://img.shields.io/badge/License-MIT-yellow.svg?style=for-the-badge)](LICENSE)

> **"The question isn't *whether* AI should be moral, but *when*."**

**EthicaAI** formalizes Amartya Sen's **Meta-Ranking** theory (preferences over preferences) as a dynamic mechanism in Multi-Agent Reinforcement Learning. We demonstrate that _Situational Commitment_ â€” morality conditional on survival â€” is the only Evolutionarily Stable Strategy across 8 environments, 7 SVO conditions, and up to 1,000 agents.

<p align="center">
  <a href="https://ethicaai.vercel.app"><strong>ğŸŒ Interactive Dashboard (74 Figures)</strong></a> &nbsp;|&nbsp;
  <a href="paper_english.md"><strong>ğŸ“„ Full Paper (35 Sections)</strong></a> &nbsp;|&nbsp;
  <a href="paper/neurips2026_main.tex"><strong>ğŸ“ NeurIPS LaTeX</strong></a>
</p>

---

## ğŸ”¬ Key Findings

| # | Finding | Evidence |
|:-:|---------|---------|
| **1** | Dynamic meta-ranking (Î»_t) significantly enhances collective welfare | p<0.001 (LMM), Cohen's fÂ²=0.40 |
| **2** | Emergent **role specialization** (Cleaners vs Eaters) | Ïƒ divergence p<0.0001 |
| **3** | Only "Situational Commitment" survives as **ESS** | 5-theory comparison, 200-gen replicator |
| **4** | **Scale invariant** from 20 to 1,000 agents | SII â‰ˆ 1.0, 1.32ms/agent |
| **5** | **Byzantine robust** at 50% adversarial population | Coop=1.000, 100% sustainability |
| **6** | SVO accounts for **79.8%** of Î»_t determination | SHAP attribution analysis |

---

## ğŸ› ï¸ Installation

```bash
# Clone & setup
git clone https://github.com/Yesol-Pilot/EthicaAI.git
cd EthicaAI

python -m venv ethica_env
source ethica_env/bin/activate  # Windows: ethica_env\Scripts\activate
pip install -r requirements.txt
```

**Requirements**: Python 3.10+, CUDA 12+ (optional, for GPU acceleration)

---

## ğŸš€ Quick Start

### Reproduce All Results (One Command)
```bash
# All 38 analysis modules (Phase G â†’ Q)
python reproduce.py

# Specific phase only
python reproduce.py --phase P  # Phase P (Scale, LMM, Mechanism Design, etc.)
python reproduce.py --phase Q  # Phase Q (Moran, GNN, Interpretability, Policy)

# Quick demo
python reproduce.py --quick
```

### Docker (Zero Setup)
```bash
# Build & run (generates all 74 figures)
docker build -t ethicaai .
docker run -v $(pwd)/output:/ethicaai/simulation/outputs/reproduce ethicaai

# Specific phase
docker run ethicaai python reproduce.py --phase P
```

### Run Individual Experiments
```bash
# Phase P: Deepening
python -m simulation.jax.analysis.scale_1000 simulation/outputs/reproduce       # P1: 1000-agent scale
python -m simulation.jax.analysis.lmm_causal_forest simulation/outputs/reproduce # P2: LMM + HTE
python -m simulation.jax.analysis.continuous_pgg simulation/outputs/reproduce     # P3: Continuous PGG
python -m simulation.jax.analysis.network_topology simulation/outputs/reproduce   # P4: Network effects
python -m simulation.jax.analysis.mechanism_design simulation/outputs/reproduce   # P5: IC/IR/NE
python -m simulation.jax.analysis.adversarial_robustness simulation/outputs/reproduce # P6: Byzantine

# Phase Q: Novel Contributions
python -m simulation.jax.analysis.moran_process simulation/outputs/reproduce     # Q2: Moran Process
python -m simulation.jax.analysis.moral_theories simulation/outputs/reproduce    # Q3: 5 Moral Theories
python -m simulation.jax.analysis.gnn_agent simulation/outputs/reproduce         # Q4: GNN Agents
python -m simulation.jax.analysis.interpretability simulation/outputs/reproduce  # Q5: Mechanistic
python -m simulation.jax.analysis.policy_implications simulation/outputs/reproduce # Q6: Policy
```

---

## ğŸ“Š 74 Figures

All figures available at [ethicaai.vercel.app](https://ethicaai.vercel.app).

| Phase | Figures | Content |
|:-----:|:-------:|---------|
| **G** (Core) | 1â€“18 | Convergence, static/dynamic Î», sensitivity, cross-env |
| **H** (Evolution) | 9â€“14 | Evolutionary competition, mechanism decomposition |
| **M** (Extended) | 19â€“30 | Full sweep, mixed-SVO, communication, continuous PGG |
| **N** (Advanced) | 31â€“38 | MAPPO, partial obs, multi-resource, LLM comparison |
| **O** (Real-world) | 39â€“48 | Climate, vaccine, AI governance, Human-AI pilot |
| **P** (Deepening) | 49â€“62 | Scale 1000, LMM, continuous, network, mechanism, adversarial |
| **Q** (Novel) | 53â€“70 | Moral theories, Moran, interpretability, policy, GNN |

---

## ğŸ“‚ Repository Structure

```
EthicaAI/
â”œâ”€â”€ simulation/
â”‚   â””â”€â”€ jax/
â”‚       â”œâ”€â”€ analysis/              # 38 analysis modules
â”‚       â”œâ”€â”€ environments/          # Cleanup, IPD, PGG, Harvest, Network
â”‚       â”œâ”€â”€ training/              # MAPPO training pipeline
â”‚       â””â”€â”€ run_full_pipeline.py   # End-to-end execution
â”œâ”€â”€ paper/                         # NeurIPS 2026 LaTeX (Main 8p + Supplementary 30p)
â”œâ”€â”€ site/                          # Interactive dashboard (Vercel)
â”œâ”€â”€ reproduce.py                   # One-command reproduction (38 modules)
â”œâ”€â”€ Dockerfile                     # Docker reproducibility package
â”œâ”€â”€ requirements.txt               # Python dependencies
â”œâ”€â”€ paper_english.md               # Full paper (35 sections)
â””â”€â”€ paper_korean.md                # Full paper (Korean)
```

---

## ğŸ“ˆ Reproduction Pipeline

```
$ python reproduce.py
============================================================
  EthicaAI Reproduction Pipeline
  Phase: all  |  Mode: Full  |  Modules: 38
============================================================
  âœ“ G1â€“G5: Core validation (convergence, sensitivity, cross-env)
  âœ“ H1â€“H2: Evolutionary competition, mechanism decomposition
  âœ“ M1â€“M4: Full sweep, mixed-SVO, communication, continuous
  âœ“ N1â€“N4: MAPPO, partial obs, multi-resource, LLM
  âœ“ O1â€“O8: Climate, vaccine, governance, Human-AI pilot
  âœ“ P1â€“P6: Scale 1000, LMM, continuous, network, mechanism, adversarial
  âœ“ Q2â€“Q6: Moran, moral theories, GNN, interpretability, policy

  Total: 38/38 succeeded
  Figures: 74 generated
  ğŸ‰ ì „ì²´ ì¬í˜„ ì„±ê³µ!
```

---

## ğŸ“œ Citation

```bibtex
@article{heo2026ethicaai,
  title={Beyond Homo Economicus: Computational Verification of Amartya Sen's
         Meta-Ranking Theory in Multi-Agent Social Dilemmas},
  author={Heo, Yesol},
  journal={arXiv preprint arXiv:2602.XXXXX},
  year={2026},
  note={74 figures, 38 modules, 8 environments, NeurIPS 2026}
}
```

---

## ğŸ“„ License

MIT License. See [LICENSE](LICENSE) for details.

> *Built with â¤ï¸ by the Antigravity Team.*
