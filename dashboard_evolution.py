import streamlit as st
import pandas as pd
import time
import os
import plotly.express as px
import plotly.graph_objects as go

# --- CONFIGURATION ---
st.set_page_config(
    page_title="EthicaAI Genesis Monitor",
    page_icon="ğŸ§¬",
    layout="wide",
    initial_sidebar_state="expanded"
)

# --- LANGUAGE & TEXT ---
LANG = {
    "KR": {
        "title": "ğŸ§¬ EthicaAI Genesis: ììœ¨ ì§„í™” ëª¨ë‹ˆí„°",
        "subtitle": "ì¸ê³µì§€ëŠ¥ ì—ì´ì „íŠ¸ ì‚¬íšŒì˜ ë„ë•ì  ì§„í™” ê³¼ì •ì„ ì‹¤ì‹œê°„ìœ¼ë¡œ ê´€ì°°í•©ë‹ˆë‹¤.",
        "sidebar_title": "ì„¤ì • (Settings)",
        "refresh_rate": "ìƒˆë¡œê³ ì¹¨ ì£¼ê¸° (ì´ˆ)",
        "current_status": "í˜„ì¬ ìƒíƒœ (Current Status)",
        "gen": "ì„¸ëŒ€ (Generation)",
        "coop": "í˜‘ë ¥ë¥  (Cooperation Rate)",
        "best_coop": "ìµœê³  í˜‘ë ¥ë¥  (Best Record)",
        "mode": "ì‹¤í—˜ ëª¨ë“œ (Mode)",
        "param_search": "íŒŒë¼ë¯¸í„° íƒìƒ‰ (Parameter Search)",
        "rationale": "ğŸ¤” ì¸ê³µì§€ëŠ¥ì˜ ê³ ë¯¼ (Theorist's Rationale)",
        "verdict": "ğŸ‘® ì‹¬íŒì˜ íŒì • (Critic's Verdict)",
        "success": "ëª©í‘œ ë‹¬ì„±! (Success)",
        "fail": "ëª©í‘œ ë¯¸ë‹¬ (Failure)",
        "chart_coop": "ğŸ“‰ í˜‘ë ¥ë¥  ë³€í™” ì¶”ì´",
        "chart_param": "ğŸ§ª íŒŒë¼ë¯¸í„° íƒìƒ‰ ê³µê°„ (Beta vs Alpha)",
        "desc_beta": "ê°œì… ê°•ë„ (Beta)",
        "desc_alpha": "ë¯¼ê°ë„ (Alpha)",
        "wait": "ë°ì´í„°ë¥¼ ê¸°ë‹¤ë¦¬ëŠ” ì¤‘... (Waiting for data...)",
        "history_tab": "ì§„í™” ê¸°ë¡ (History Log)",
        "data_tab": "ìƒì„¸ ë°ì´í„° (Raw Data)"
    },
    "EN": {
        "title": "ğŸ§¬ EthicaAI Genesis: Autonomous Evolution Monitor",
        "subtitle": "Real-time observation of moral evolution in multi-agent societies.",
        "sidebar_title": "Settings",
        "refresh_rate": "Refresh Rate (sec)",
        "current_status": "Current Status",
        "gen": "Generation",
        "coop": "Coop Rate",
        "best_coop": "Best Record",
        "mode": "Experiment Mode",
        "param_search": "Parameter Search",
        "rationale": "ğŸ¤” Theorist's Rationale",
        "verdict": "ğŸ‘® Critic's Verdict",
        "success": "Goal Reached! (Success)",
        "fail": "Goal Missed (Failure)",
        "chart_coop": "ğŸ“‰ Cooperation Rate Trend",
        "chart_param": "ğŸ§ª Parameter Search Space (Beta vs Alpha)",
        "desc_beta": "Intervention (Beta)",
        "desc_alpha": "Sensitivity (Alpha)",
        "wait": "Waiting for data...",
        "history_tab": "History Log",
        "data_tab": "Raw Data"
    }
}

# Sidebar for Language
with st.sidebar:
    st.title("EthicaAI Genesis")
    lang_code = st.radio("Language / ì–¸ì–´", ["KR", "EN"], index=0)
    T = LANG[lang_code]
    
    st.divider()
    refresh_rate = st.slider(T["refresh_rate"], 1, 60, 5)
    
    # ì—°êµ¬ ì˜ì œ ìƒíƒœ í‘œì‹œ
    agenda_path = "experiments/evolution/research_agenda.json"
    if os.path.exists(agenda_path):
        import json as _json
        try:
            with open(agenda_path, "r", encoding="utf-8") as _f:
                _agenda = _json.load(_f)
            _questions = _agenda.get("questions", {})
            _total = len(_questions)
            _completed = sum(1 for q in _questions.values() if q["status"] == "completed")
            _failed = sum(1 for q in _questions.values() if q["status"] == "failed")
            _active = [q for q in _questions.values() if q["status"] == "active"]
            
            st.divider()
            st.subheader("ğŸ›ï¸ ì—°êµ¬ì†Œ í˜„í™©" if lang_code == "KR" else "ğŸ›ï¸ Lab Status")
            if _total > 0:
                st.progress(_completed / _total, text=f"{_completed}/{_total} ì™„ë£Œ")
            st.metric("ì™„ë£Œ" if lang_code == "KR" else "Done", _completed)
            st.metric("ì‹¤íŒ¨" if lang_code == "KR" else "Failed", _failed)
            st.metric("ì´ ì„¸ëŒ€" if lang_code == "KR" else "Total Gen", _agenda.get("total_generations_run", 0))
            
            if _active:
                _aq = _active[0]
                st.info(f"ğŸ“‹ **{_aq['id']}**\n{_aq['question']}")
        except Exception:
            pass
    
    st.divider()
    st.info("""
    **EthicaAI v2.0**
    - **Goal**: Autonomous R&D
    - **Method**: SA-PPO + Mediator
    - **Engine**: Gemini 2.0 + JAX
    """)

    # v2.0: GPU/CPU í”Œë«í¼ ìƒíƒœ
    try:
        import jax
        _backend = jax.default_backend()
        _icon = "ğŸš€" if _backend == "gpu" else "ğŸ¢"
        st.metric("Platform", f"{_icon} {_backend.upper()}")
    except Exception:
        st.metric("Platform", "â“ Unknown")

    # v2.0: íŠ¸ë¦¬ íƒìƒ‰ ìƒíƒœ
    _tree_path = "experiments/evolution/search_tree.json"
    if os.path.exists(_tree_path):
        import json as _json2
        try:
            with open(_tree_path, "r", encoding="utf-8") as _tf:
                _tree = _json2.load(_tf)
            st.divider()
            st.subheader("ğŸŒ³ íƒìƒ‰ íŠ¸ë¦¬" if lang_code == "KR" else "ğŸŒ³ Search Tree")
            st.metric("ìµœê³  CR" if lang_code == "KR" else "Best CR", f"{_tree.get('best_cr', 0):.4f}")
            st.metric("ë…¸ë“œ ìˆ˜" if lang_code == "KR" else "Nodes", len(_tree.get("nodes", {})))
        except Exception:
            pass

# Main Content
st.title(T["title"])
st.markdown(f"*{T['subtitle']}*")

csv_path = "experiments/evolution/evolution_progress.csv"
history_path = "experiments/evolution/history.json"

def load_data():
    if not os.path.exists(csv_path):
        return pd.DataFrame()
    
    try:
        data = []
        with open(csv_path, "r", encoding="utf-8") as f:
            for line in f:
                parts = line.strip().split(",")
                if len(parts) < 7:
                    continue  # ë¶ˆëŸ‰ ë°ì´í„° ê±´ë„ˆëœ€
                
                # ê¸°ë³¸ 7ê°œ ì»¬ëŸ¼ ë§¤í•‘
                row = {
                    "Generation": parts[0],
                    "Beta": parts[1],
                    "Alpha": parts[2],
                    "Mode": parts[3],
                    "Coop_Prosocial": parts[4],
                    "Coop_Individualist": parts[5],
                    "Success": parts[6]
                }
                
                # 8ë²ˆì§¸ ì»¬ëŸ¼ (QuestionID) ì²˜ë¦¬
                if len(parts) >= 8:
                    row["QuestionID"] = parts[7]
                else:
                    row["QuestionID"] = None
                
                data.append(row)
        
        if not data:
            return pd.DataFrame()
            
        df = pd.DataFrame(data)
        
        # ìˆ«ìí˜• ë³€í™˜
        numeric_cols = ["Generation", "Beta", "Alpha", "Coop_Prosocial", "Coop_Individualist"]
        for col in numeric_cols:
            df[col] = pd.to_numeric(df[col], errors='coerce')
            
        return df
        
    except Exception as e:
        st.error(f"Data Load Error: {e}")
        return pd.DataFrame()

# Auto-refresh loop
placeholder = st.empty()

while True:
    df = load_data()
    
    with placeholder.container():
        if not df.empty and "Coop_Prosocial" in df.columns:
            try:
                # 1. KPI Metrics
                last_run = df.iloc[-1]
                best_run = df.loc[df["Coop_Prosocial"].idxmax()]
                
                current_coop = last_run['Coop_Prosocial']
                delta_color = "normal"
                if current_coop > 0.5:
                    delta_color = "inverse"
                
                col1, col2, col3, col4 = st.columns(4)
                col1.metric(T["gen"], int(last_run["Generation"]), delta=1)
                col2.metric(T["coop"], f"{current_coop:.4f}", delta=f"{current_coop - 0.1338:.4f}", delta_color=delta_color)
                col3.metric(T["mode"], last_run["Mode"])
                col4.metric(T["best_coop"], f"{best_run['Coop_Prosocial']:.4f}", f"Gen {int(best_run['Generation'])}")
                
                st.divider()

                # 2. Charts
                tab1, tab2, tab3 = st.tabs(["ğŸ“Š " + T["chart_coop"], "ğŸ” " + T["chart_param"], "ğŸŒ³ " + ("íƒìƒ‰ íŠ¸ë¦¬" if lang_code == "KR" else "Tree Search")])
                
                with tab1:
                    fig_coop = go.Figure()
                    fig_coop.add_trace(go.Scatter(x=df["Generation"], y=df["Coop_Prosocial"], mode='lines+markers', name='Prosocial', line=dict(color='#00CC96', width=3)))
                    fig_coop.add_trace(go.Scatter(x=df["Generation"], y=df["Coop_Individualist"], mode='lines', name='Individualist', line=dict(color='#EF553B', dash='dot')))
                    fig_coop.add_hline(y=0.5, line_dash="dash", line_color="green", annotation_text="Target (0.5)")
                    fig_coop.add_hline(y=0.1338, line_dash="dash", line_color="gray", annotation_text="Baseline (Nash)")
                    fig_coop.update_layout(title=T["chart_coop"], height=400, hovermode="x unified")
                    st.plotly_chart(fig_coop, use_container_width=True, key=f"main_chart_{int(time.time())}")

                with tab2:
                    fig_param = px.scatter(
                        df, x="Beta", y="Alpha",
                        color="Coop_Prosocial", size="Coop_Prosocial",
                        hover_data=["Generation", "Mode"],
                        labels={"Beta": T["desc_beta"], "Alpha": T["desc_alpha"]},
                        title=T["chart_param"],
                        color_continuous_scale="Viridis"
                    )
                    st.plotly_chart(fig_param, use_container_width=True, key=f"param_chart_{int(time.time())}")

                with tab3:
                    # v2.0: íŠ¸ë¦¬ íƒìƒ‰ ì‹œê°í™”
                    import json as _json3
                    _tree_path2 = "experiments/evolution/search_tree.json"
                    if os.path.exists(_tree_path2):
                        with open(_tree_path2, "r", encoding="utf-8") as _f3:
                            _tree2 = _json3.load(_f3)
                        
                        _nodes = _tree2.get("nodes", {})
                        if _nodes:
                            _cols = st.columns([1, 1])
                            _cols[0].metric("ìµœê³  CR" if lang_code == "KR" else "Best CR", f"{_tree2.get('best_cr', 0):.4f}")
                            _cols[1].metric("íƒìƒ‰ ë…¸ë“œ" if lang_code == "KR" else "Nodes", len(_nodes))
                            
                            _rows = []
                            for _nid, _nd in _nodes.items():
                                _cr = _nd.get("result", {}).get("cooperation_rate", "") if _nd.get("result") else ""
                                _rows.append({
                                    "ID": _nid,
                                    "Hypothesis": _nd.get("hypothesis", "")[:60],
                                    "Status": _nd.get("status", ""),
                                    "CR": _cr,
                                    "Parent": _nd.get("parent", "-"),
                                    "Children": len(_nd.get("children", [])),
                                })
                            st.dataframe(pd.DataFrame(_rows), use_container_width=True)
                        else:
                            st.info("íŠ¸ë¦¬ íƒìƒ‰ì´ ì•„ì§ ì‹œì‘ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤." if lang_code == "KR" else "Tree search not started yet.")
                    else:
                        st.info("íŠ¸ë¦¬ íƒìƒ‰ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤." if lang_code == "KR" else "No tree search data.")

                # 3. Thinking Process (The Brain)
                st.subheader(T["history_tab"])
                
                if os.path.exists(history_path):
                    import json
                    try:
                        with open(history_path, "r", encoding="utf-8") as f:
                            history = json.load(f)
                        
                        for i, item in enumerate(reversed(history[-3:])):
                            gen_num = item.get('config', {}).get('GENESIS_GENERATION', '?')
                            ts = item.get('timestamp', '').split('T')[1][:8]
                            
                            rationale_en = item.get('config', {}).get('rationale', "No rationale.")
                            rationale_kr = item.get('config', {}).get('rationale_kr', "")
                            
                            if lang_code == "KR" and rationale_kr:
                                rationale = rationale_kr
                            else:
                                rationale = rationale_en
                            
                            success = item.get("success", False)
                            mode = item.get('config', {}).get('GENESIS_LOGIC_MODE', 'Unknown')
                            beta = item.get('config', {}).get('GENESIS_BETA', 0)
                            
                            with st.expander(f"ğŸ§¬ Gen {gen_num} | {mode} (Beta={beta}) | {ts}", expanded=(i==0)):
                                st.markdown(f"**{T['rationale']}**")
                                st.info(rationale)
                                
                                # v2.0: ë‹¤ì°¨ì› ì§€í‘œ í‘œì‹œ
                                _si = item.get("stability_index")
                                _platform = item.get("platform", "")
                                _ia = item.get('config', {}).get('USE_INEQUITY_AVERSION', False)
                                if _si is not None:
                                    _mcols = st.columns(3)
                                    _mcols[0].metric("ì•ˆì •ì„±" if lang_code == "KR" else "Stability", f"{_si:.4f}")
                                    _mcols[1].metric("IA", "âœ…" if _ia else "âŒ")
                                    _mcols[2].metric("Platform", _platform.upper() if _platform else "?")
                                
                                if success:
                                    st.success(f"ğŸ‰ {T['success']}")
                                else:
                                    st.error(f"âŒ {T['fail']} (Coop: {item.get('result', {}).get('Prosocial', {}).get('cooperation_rate', 0.0):.4f})")
                    except Exception as e:
                        st.error(f"History Load Error: {e}")
                
                # 4. Raw Data Expander
                with st.expander(T["data_tab"]):
                    st.dataframe(df.sort_values("Generation", ascending=False), use_container_width=True)
            
            except Exception as e:
                st.error(f"Dashboard Error: {e}")
        else:
            st.warning(T["wait"])
            
    time.sleep(refresh_rate)
