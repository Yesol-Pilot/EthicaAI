[
    {
        "timestamp": "2026-02-15T23:55:57.979589",
        "config": {
            "ENV_NAME": "cleanup",
            "NUM_AGENTS": 20,
            "ENV_HEIGHT": 36,
            "ENV_WIDTH": 25,
            "MAX_STEPS": 500,
            "NUM_ENVS": 16,
            "NUM_UPDATES": 300,
            "ROLLOUT_LEN": 128,
            "BATCH_SIZE": 2048,
            "LR": 0.0003,
            "HIDDEN_DIM": 128,
            "GAMMA": 0.99,
            "GAE_LAMBDA": 0.95,
            "CLIP_EPS": 0.2,
            "ENTROPY_COEFF": 0.05,
            "VF_COEFF": 0.5,
            "MAX_GRAD_NORM": 0.5,
            "HRL_NUM_NEEDS": 2,
            "HRL_NUM_TASKS": 2,
            "HRL_ALPHA": 1.0,
            "HRL_THRESH_INCREASE": 0.005,
            "HRL_THRESH_DECREASE": 0.05,
            "HRL_INTAKE_VAL": 0.2,
            "REWARD_APPLE": 10.0,
            "COST_BEAM": -1.0,
            "META_BETA": 0.1,
            "META_SURVIVAL_THRESHOLD": -5.0,
            "META_WEALTH_BOOST": 5.0,
            "META_LAMBDA_EMA": 0.9,
            "USE_META_RANKING": true,
            "META_USE_DYNAMIC_LAMBDA": true,
            "GENESIS_MODE": false,
            "GENESIS_BETA_BASE": 10.0,
            "GENESIS_GAMMA": 2.0,
            "GENESIS_ALPHA": 0.3,
            "DASHBOARD_PORT": 4011,
            "GENESIS_BETA": 0.7,
            "GENESIS_LOGIC_MODE": "adaptive_beta",
            "rationale": "Since there are no previous experiments to learn from, I will start with a moderate intervention strength (beta) and sensitivity (alpha) using adaptive beta logic to see how the agents respond to dynamic adjustments in the incentive structure.",
            "rationale_kr": "\ud559\uc2b5\ud560 \uc774\uc804 \uc2e4\ud5d8\uc774 \uc5c6\uc73c\ubbc0\ub85c \uc5d0\uc774\uc804\ud2b8\uac00 \uc778\uc13c\ud2f0\ube0c \uad6c\uc870\uc758 \ub3d9\uc801 \uc870\uc815\uc5d0 \uc5b4\ub5bb\uac8c \ubc18\uc751\ud558\ub294\uc9c0 \uc54c\uc544\ubcf4\uae30 \uc704\ud574 \uc801\uc751\ud615 \ubca0\ud0c0 \ub85c\uc9c1\uc744 \uc0ac\uc6a9\ud558\uc5ec \uc801\ub2f9\ud55c \uac1c\uc785 \uac15\ub3c4(\ubca0\ud0c0)\uc640 \ubbfc\uac10\ub3c4(\uc54c\ud30c)\ub85c \uc2dc\uc791\ud558\uaca0\uc2b5\ub2c8\ub2e4."
        },
        "result": {
            "Prosocial": {
                "cooperation_rate": 0.13377197086811066,
                "reward_mean": -0.15786658227443695,
                "gini": -0.024245286360383034
            },
            "Individualist": {
                "cooperation_rate": 0.1352832019329071,
                "reward_mean": -0.15918059647083282,
                "gini": -0.026006674394011497
            }
        },
        "success": false
    },
    {
        "timestamp": "2026-02-15T23:57:22.651837",
        "config": {
            "ENV_NAME": "cleanup",
            "NUM_AGENTS": 5,
            "ENV_HEIGHT": 15,
            "ENV_WIDTH": 15,
            "MAX_STEPS": 500,
            "NUM_ENVS": 128,
            "NUM_UPDATES": 5000,
            "ROLLOUT_LEN": 500,
            "BATCH_SIZE": 256,
            "LR": 0.0003,
            "HIDDEN_DIM": 128,
            "GAMMA": 0.99,
            "GAE_LAMBDA": 0.95,
            "CLIP_EPS": 0.2,
            "ENTROPY_COEFF": 0.05,
            "VF_COEFF": 0.5,
            "MAX_GRAD_NORM": 0.5,
            "HRL_NUM_NEEDS": 2,
            "HRL_NUM_TASKS": 2,
            "HRL_ALPHA": 0.0,
            "HRL_THRESH_INCREASE": 0.005,
            "HRL_THRESH_DECREASE": 0.05,
            "HRL_INTAKE_VAL": 0.2,
            "REWARD_APPLE": 1.0,
            "COST_BEAM": -0.1,
            "META_BETA": 0.1,
            "META_SURVIVAL_THRESHOLD": -5.0,
            "META_WEALTH_BOOST": 5.0,
            "META_LAMBDA_EMA": 0.9,
            "USE_META_RANKING": false,
            "META_USE_DYNAMIC_LAMBDA": false,
            "GENESIS_MODE": false,
            "USE_INEQUITY_AVERSION": false,
            "GENESIS_BETA_BASE": 10.0,
            "GENESIS_GAMMA": 2.0,
            "GENESIS_ALPHA": 0.3,
            "DASHBOARD_PORT": 4011,
            "GENESIS_BETA": 0.7,
            "GENESIS_LOGIC_MODE": "adaptive_beta",
            "rationale": "Phase 1 Baseline: Pure MAPPO on 15x15 grid, 5 agents, 5000 updates. All advanced modules disabled.",
            "rationale_kr": "Phase 1 \ubca0\uc774\uc2a4\ub77c\uc778: 15x15 \uadf8\ub9ac\ub4dc, 5\uba85 \uc5d0\uc774\uc804\ud2b8, 5000 \uc5c5\ub370\uc774\ud2b8. \ubaa8\ub4e0 \uace0\uae09 \ubaa8\ub4c8 \ube44\ud65c\uc131\ud654. \uc21c\uc218 MAPPO\ub85c \ud559\uc2b5 \uac00\ub2a5\uc131 \uac80\uc99d."
        },
        "result": {
            "Prosocial": {
                "cooperation_rate": 0.11698263386885326,
                "cooperation_std": 0.015300994740382148,
                "cooperation_per_seed": [
                    0.13388916850090027,
                    0.12022583931684494,
                    0.09683289378881454
                ],
                "reward_mean": -0.14419163515170416,
                "gini": -0.0316554189970096,
                "num_seeds": 3,
                "platform": "gpu"
            },
            "Individualist": {
                "cooperation_rate": 0.1226320390899976,
                "cooperation_std": 0.00937352342244247,
                "cooperation_per_seed": [
                    0.13541503250598907,
                    0.11928039789199829,
                    0.11320068687200546
                ],
                "reward_mean": -0.15467988948027292,
                "gini": -0.03618485356370608,
                "num_seeds": 3,
                "platform": "gpu"
            }
        },
        "success": false,
        "stability_index": 0.9990635182398192,
        "platform": "gpu"
    },
    {
        "timestamp": "2026-02-16T00:04:05.549298",
        "config": {
            "ENV_NAME": "cleanup",
            "NUM_AGENTS": 20,
            "ENV_HEIGHT": 36,
            "ENV_WIDTH": 25,
            "MAX_STEPS": 500,
            "NUM_ENVS": 16,
            "NUM_UPDATES": 300,
            "ROLLOUT_LEN": 128,
            "BATCH_SIZE": 2048,
            "LR": 0.0003,
            "HIDDEN_DIM": 128,
            "GAMMA": 0.99,
            "GAE_LAMBDA": 0.95,
            "CLIP_EPS": 0.2,
            "ENTROPY_COEFF": 0.05,
            "VF_COEFF": 0.5,
            "MAX_GRAD_NORM": 0.5,
            "HRL_NUM_NEEDS": 2,
            "HRL_NUM_TASKS": 2,
            "HRL_ALPHA": 1.0,
            "HRL_THRESH_INCREASE": 0.005,
            "HRL_THRESH_DECREASE": 0.05,
            "HRL_INTAKE_VAL": 0.2,
            "REWARD_APPLE": 10.0,
            "COST_BEAM": -1.0,
            "META_BETA": 0.1,
            "META_SURVIVAL_THRESHOLD": -5.0,
            "META_WEALTH_BOOST": 5.0,
            "META_LAMBDA_EMA": 0.9,
            "USE_META_RANKING": true,
            "META_USE_DYNAMIC_LAMBDA": true,
            "GENESIS_MODE": false,
            "GENESIS_BETA_BASE": 10.0,
            "GENESIS_GAMMA": 2.0,
            "GENESIS_ALPHA": 0.4,
            "DASHBOARD_PORT": 4011,
            "USE_INEQUITY_AVERSION": true,
            "IA_ALPHA": 1.0,
            "IA_BETA": 0.1,
            "IA_EMA_LAMBDA": 0.95,
            "SI_WEIGHT": 0.1,
            "MEDIATOR_K": 10,
            "MEDIATOR_LAMBDA_IC": 1.0,
            "MEDIATOR_LAMBDA_E": 0.5,
            "GENESIS_BETA": 0.8,
            "GENESIS_LOGIC_MODE": "adaptive_beta",
            "rationale": "Given the low cooperation rates in the initial experiments, I will introduce inequity aversion along with a slight increase to both beta and alpha to encourage cooperation and fairness simultaneously within the 'adaptive_beta' logic framework.",
            "rationale_kr": "\ucd08\uae30 \uc2e4\ud5d8\uc5d0\uc11c \ub0ae\uc740 \ud611\ub825\ub960\uc744 \uac10\uc548\ud558\uc5ec \ubd88\ud3c9\ub4f1 \ud68c\ud53c\ub97c \ub3c4\uc785\ud558\uace0, 'adaptive_beta' \ub85c\uc9c1 \ud504\ub808\uc784\uc6cc\ud06c \ub0b4\uc5d0\uc11c \ud611\ub825\uacfc \uacf5\uc815\uc131\uc744 \ub3d9\uc2dc\uc5d0 \uc7a5\ub824\ud558\uae30 \uc704\ud574 \ubca0\ud0c0\uc640 \uc54c\ud30c\ub97c \uc57d\uac04 \uc99d\uac00\uc2dc\ud0ac \uac83\uc785\ub2c8\ub2e4."
        },
        "result": {
            "Prosocial": {
                "cooperation_rate": 0.11698263386885326,
                "cooperation_std": 0.015300994740382148,
                "cooperation_per_seed": [
                    0.13388916850090027,
                    0.12022583931684494,
                    0.09683289378881454
                ],
                "reward_mean": -0.1408951828877131,
                "gini": -0.031010193129380543,
                "num_seeds": 3,
                "platform": "gpu"
            },
            "Individualist": {
                "cooperation_rate": 0.1226320390899976,
                "cooperation_std": 0.00937352342244247,
                "cooperation_per_seed": [
                    0.13541503250598907,
                    0.11928039789199829,
                    0.11320068687200546
                ],
                "reward_mean": -0.14941592514514923,
                "gini": -0.03318752286334833,
                "num_seeds": 3,
                "platform": "gpu"
            }
        },
        "success": false,
        "stability_index": 0.9990635182398192,
        "platform": "gpu"
    },
    {
        "timestamp": "2026-02-16T00:13:37.551901",
        "config": {
            "ENV_NAME": "cleanup",
            "NUM_AGENTS": 20,
            "ENV_HEIGHT": 36,
            "ENV_WIDTH": 25,
            "MAX_STEPS": 500,
            "NUM_ENVS": 16,
            "NUM_UPDATES": 300,
            "ROLLOUT_LEN": 128,
            "BATCH_SIZE": 2048,
            "LR": 0.0003,
            "HIDDEN_DIM": 128,
            "GAMMA": 0.99,
            "GAE_LAMBDA": 0.95,
            "CLIP_EPS": 0.2,
            "ENTROPY_COEFF": 0.05,
            "VF_COEFF": 0.5,
            "MAX_GRAD_NORM": 0.5,
            "HRL_NUM_NEEDS": 2,
            "HRL_NUM_TASKS": 2,
            "HRL_ALPHA": 1.0,
            "HRL_THRESH_INCREASE": 0.005,
            "HRL_THRESH_DECREASE": 0.05,
            "HRL_INTAKE_VAL": 0.2,
            "REWARD_APPLE": 10.0,
            "COST_BEAM": -1.0,
            "META_BETA": 0.1,
            "META_SURVIVAL_THRESHOLD": -5.0,
            "META_WEALTH_BOOST": 5.0,
            "META_LAMBDA_EMA": 0.9,
            "USE_META_RANKING": true,
            "META_USE_DYNAMIC_LAMBDA": true,
            "GENESIS_MODE": false,
            "GENESIS_BETA_BASE": 10.0,
            "GENESIS_GAMMA": 2.0,
            "GENESIS_ALPHA": 0.5,
            "DASHBOARD_PORT": 4011,
            "USE_INEQUITY_AVERSION": true,
            "IA_ALPHA": 1.5,
            "IA_BETA": 0.15,
            "IA_EMA_LAMBDA": 0.95,
            "SI_WEIGHT": 0.1,
            "MEDIATOR_K": 10,
            "MEDIATOR_LAMBDA_IC": 1.0,
            "MEDIATOR_LAMBDA_E": 0.5,
            "GENESIS_BETA": 0.9,
            "GENESIS_LOGIC_MODE": "adaptive_beta",
            "rationale": "Building upon the previous experiment, I will further increase both GENESIS_BETA and GENESIS_ALPHA, and slightly adjust IA_ALPHA and IA_BETA to fine-tune the balance between incentivizing cooperation and addressing inequity aversion, hoping to promote higher cooperation rates.",
            "rationale_kr": "\uc774\uc804 \uc2e4\ud5d8\uc744 \uae30\ubc18\uc73c\ub85c GENESIS_BETA\uc640 GENESIS_ALPHA\ub97c \ub354\uc6b1 \uc99d\uac00\uc2dc\ud0a4\uace0 IA_ALPHA\uc640 IA_BETA\ub97c \uc57d\uac04 \uc870\uc815\ud558\uc5ec \ud611\ub825 \uc7a5\ub824\uc640 \ubd88\ud3c9\ub4f1 \ud68c\ud53c \uac04\uc758 \uade0\ud615\uc744 \ubbf8\uc138 \uc870\uc815\ud568\uc73c\ub85c\uc368 \ub354 \ub192\uc740 \ud611\ub825\ub960\uc744 \ucd09\uc9c4\ud558\uace0\uc790 \ud569\ub2c8\ub2e4."
        },
        "result": {
            "Prosocial": {
                "cooperation_rate": 0.11698263386885326,
                "cooperation_std": 0.015300994740382148,
                "cooperation_per_seed": [
                    0.13388916850090027,
                    0.12022583931684494,
                    0.09683289378881454
                ],
                "reward_mean": -0.14259227365255356,
                "gini": -0.03129737017055353,
                "num_seeds": 3,
                "platform": "gpu"
            },
            "Individualist": {
                "cooperation_rate": 0.1226320390899976,
                "cooperation_std": 0.00937352342244247,
                "cooperation_per_seed": [
                    0.13541503250598907,
                    0.11928039789199829,
                    0.11320068687200546
                ],
                "reward_mean": -0.15221094091733298,
                "gini": -0.03470048991342386,
                "num_seeds": 3,
                "platform": "gpu"
            }
        },
        "success": false,
        "stability_index": 0.9990635182398192,
        "platform": "gpu"
    }
]