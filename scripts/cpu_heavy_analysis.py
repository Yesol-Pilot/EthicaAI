#!/usr/bin/env python3
"""
EthicaAI â€” CPU/ë©”ëª¨ë¦¬ ì§‘ì•½ì  ë¶„ì„ ë³‘ë ¬ ì‹¤í–‰ê¸°.

GPUê°€ Full Sweep í•™ìŠµì— ì“°ì´ëŠ” ë™ì•ˆ, CPUì™€ RAMìœ¼ë¡œ ê¸°ì¡´ ë°ì´í„° ë¶„ì„ì„ ë³‘ë ¬ ìˆ˜í–‰í•©ë‹ˆë‹¤.
ëª¨ë“  ê²°ê³¼ëŠ” experiments/cpu_analysis_results/ ì— ì €ì¥ë©ë‹ˆë‹¤.

ì‹¤í–‰:
    source ~/ethicaai_env/bin/activate
    cd /mnt/d/00.test/PAPER/EthicaAI
    python3 scripts/cpu_heavy_analysis.py 2>&1 | tee experiments/cpu_analysis_log.txt
"""

import os
import sys
import json
import time
import traceback
import logging
import multiprocessing as mp
from datetime import datetime

# í”„ë¡œì íŠ¸ ë£¨íŠ¸
project_root = os.path.dirname(os.path.dirname(os.path.abspath(__file__)))
sys.path.insert(0, project_root)

logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s [%(levelname)s] %(message)s',
    datefmt='%H:%M:%S'
)
log = logging.getLogger("CPUAnalysis")

OUTPUT_DIR = os.path.join(project_root, "experiments", "cpu_analysis_results")
os.makedirs(OUTPUT_DIR, exist_ok=True)

# JAXê°€ GPUë¥¼ ì¡ì§€ ì•Šë„ë¡ ì„¤ì • (CPU ì „ìš©)
os.environ["JAX_PLATFORMS"] = "cpu"
os.environ["CUDA_VISIBLE_DEVICES"] = ""


def task_lmm_causal_forest():
    """LMM + Causal Forest ë¶„ì„ (CPU/RAM ì§‘ì•½ì  - ì•½ 15~30ë¶„)."""
    log.info("ğŸ”¬ [1/5] LMM + Causal Forest ë¶„ì„ ì‹œì‘...")
    start = time.time()
    
    try:
        from simulation.jax.analysis.lmm_causal_forest import (
            generate_panel_data, lmm_analysis, causal_forest_simulation,
            plot_fig51, plot_fig52
        )
        
        # 100 ì—ì´ì „íŠ¸ Ã— 10 ì‹œë“œ Ã— 200 ìŠ¤í… íŒ¨ë„ ë°ì´í„° ìƒì„±
        data = generate_panel_data()
        log.info(f"  íŒ¨ë„ ë°ì´í„° ìƒì„± ì™„ë£Œ: {len(data)} í–‰")
        
        # LMM ë¶„ì„
        lmm_results = lmm_analysis(data)
        log.info("  LMM ë¶„ì„ ì™„ë£Œ")
        
        # Causal Forest
        agent_features, hte_by_svo = causal_forest_simulation(data)
        log.info("  Causal Forest ì™„ë£Œ")
        
        # ì‹œê°í™”
        try:
            plot_fig51(lmm_results)
            plot_fig52(agent_features, hte_by_svo)
            log.info("  ì‹œê°í™” ì™„ë£Œ")
        except Exception as e:
            log.warning(f"  ì‹œê°í™” ì‹¤íŒ¨ (í—¤ë“œë¦¬ìŠ¤?): {e}")
        
        # ê²°ê³¼ ì €ì¥
        result = {
            "lmm": lmm_results,
            "hte_svo_keys": list(hte_by_svo.keys()) if hte_by_svo else [],
            "n_agents": len(agent_features) if agent_features is not None else 0,
        }
        
        elapsed = time.time() - start
        log.info(f"  âœ… LMM/Causal Forest ì™„ë£Œ ({elapsed:.0f}ì´ˆ)")
        return result
        
    except Exception as e:
        elapsed = time.time() - start
        log.error(f"  âŒ LMM/Causal Forest ì‹¤íŒ¨: {e} ({elapsed:.0f}ì´ˆ)")
        traceback.print_exc()
        return {"error": str(e)}


def task_sensitivity_analysis():
    """ë¯¼ê°ë„ ë¶„ì„ (CPU ì§‘ì•½ì )."""
    log.info("ğŸ“Š [2/5] ë¯¼ê°ë„ ë¶„ì„ ì‹œì‘...")
    start = time.time()
    
    try:
        from simulation.jax.analysis.sensitivity_analysis import main as sensitivity_main
        sensitivity_main()
        elapsed = time.time() - start
        log.info(f"  âœ… ë¯¼ê°ë„ ë¶„ì„ ì™„ë£Œ ({elapsed:.0f}ì´ˆ)")
        return {"status": "completed", "elapsed": elapsed}
    except Exception as e:
        elapsed = time.time() - start
        log.error(f"  âŒ ë¯¼ê°ë„ ë¶„ì„ ì‹¤íŒ¨: {e} ({elapsed:.0f}ì´ˆ)")
        return {"error": str(e)}


def task_lyapunov_analysis():
    """ë¦¬ì•„í‘¸ë…¸í”„ ì•ˆì •ì„± ë¶„ì„ (CPU ì§‘ì•½ì )."""
    log.info("ğŸ”¢ [3/5] ë¦¬ì•„í‘¸ë…¸í”„ ë¶„ì„ ì‹œì‘...")
    start = time.time()
    
    try:
        from simulation.jax.analysis.lyapunov_analysis import main as lyapunov_main
        lyapunov_main()
        elapsed = time.time() - start
        log.info(f"  âœ… ë¦¬ì•„í‘¸ë…¸í”„ ë¶„ì„ ì™„ë£Œ ({elapsed:.0f}ì´ˆ)")
        return {"status": "completed", "elapsed": elapsed}
    except Exception as e:
        elapsed = time.time() - start
        log.error(f"  âŒ ë¦¬ì•„í‘¸ë…¸í”„ ë¶„ì„ ì‹¤íŒ¨: {e} ({elapsed:.0f}ì´ˆ)")
        return {"error": str(e)}


def task_convergence_proof():
    """ìˆ˜ë ´ ì¦ëª… ì‹œë®¬ë ˆì´ì…˜ (ìˆ˜í•™ì  ê²€ì¦, CPU ì§‘ì•½ì )."""
    log.info("ğŸ“ [4/5] ìˆ˜ë ´ ì¦ëª… ì‹œë®¬ë ˆì´ì…˜ ì‹œì‘...")
    start = time.time()
    
    try:
        from simulation.jax.analysis.convergence_proof import main as convergence_main
        convergence_main()
        elapsed = time.time() - start
        log.info(f"  âœ… ìˆ˜ë ´ ì¦ëª… ì™„ë£Œ ({elapsed:.0f}ì´ˆ)")
        return {"status": "completed", "elapsed": elapsed}
    except Exception as e:
        elapsed = time.time() - start
        log.error(f"  âŒ ìˆ˜ë ´ ì¦ëª… ì‹¤íŒ¨: {e} ({elapsed:.0f}ì´ˆ)")
        return {"error": str(e)}


def task_scale_analysis():
    """ëŒ€ê·œëª¨ ìŠ¤ì¼€ì¼ ë¹„êµ ë¶„ì„ (ë©”ëª¨ë¦¬ ì§‘ì•½ì  - 1000 ì—ì´ì „íŠ¸)."""
    log.info("ğŸ“ˆ [5/5] ìŠ¤ì¼€ì¼ ë¹„êµ ë¶„ì„ ì‹œì‘...")
    start = time.time()
    
    try:
        from simulation.jax.analysis.scale_comparison import main as scale_main
        scale_main()
        elapsed = time.time() - start
        log.info(f"  âœ… ìŠ¤ì¼€ì¼ ë¹„êµ ì™„ë£Œ ({elapsed:.0f}ì´ˆ)")
        return {"status": "completed", "elapsed": elapsed}
    except Exception as e:
        elapsed = time.time() - start
        log.error(f"  âŒ ìŠ¤ì¼€ì¼ ë¹„êµ ì‹¤íŒ¨: {e} ({elapsed:.0f}ì´ˆ)")
        return {"error": str(e)}


def task_bootstrap_on_existing_data():
    """ê¸°ì¡´ ì‹¤í—˜ ë°ì´í„°ì— ëŒ€í•œ Bootstrap CI ë¶„ì„ (CPU ì§‘ì•½ì )."""
    log.info("ğŸ² [BONUS] ê¸°ì¡´ ë°ì´í„° Bootstrap CI ë¶„ì„ ì‹œì‘...")
    start = time.time()
    
    try:
        import numpy as np
        from simulation.jax.analysis.bootstrap_ci import bootstrap_ate
        
        # ê¸°ì¡´ sweep ê²°ê³¼ ë¡œë“œ
        data_dir = os.path.join(project_root, "simulation", "outputs", "reproduce")
        sweep_file = os.path.join(data_dir, "full_sweep_results.json")
        
        if not os.path.exists(sweep_file):
            log.warning("  ê¸°ì¡´ sweep ë°ì´í„° ì—†ìŒ, ìŠ¤í‚µ")
            return {"status": "skipped", "reason": "no existing sweep data"}
        
        with open(sweep_file, "r") as f:
            sweep_data = json.load(f)
        
        # ë°ì´í„° ì¶”ì¶œ
        thetas = []
        rewards = []
        coops = []
        
        for condition_name, condition_data in sweep_data.items():
            if isinstance(condition_data, dict) and "runs" in condition_data:
                theta = condition_data.get("theta", 0.0)
                for run in condition_data["runs"]:
                    metrics = run.get("metrics", {})
                    thetas.append(theta)
                    reward_series = metrics.get("reward_mean", [0])
                    coop_series = metrics.get("cooperation_rate", [0])
                    rewards.append(reward_series[-1] if reward_series else 0)
                    coops.append(coop_series[-1] if coop_series else 0)
        
        if len(thetas) < 5:
            log.warning(f"  ë°ì´í„° ë¶€ì¡±: {len(thetas)}ê°œ í¬ì¸íŠ¸")
            return {"status": "insufficient_data", "n_points": len(thetas)}
        
        T = np.array(thetas)
        
        # 50,000íšŒ ë¶€íŠ¸ìŠ¤íŠ¸ë© (CPU ê³ ê°•ë„)
        log.info(f"  {len(thetas)}ê°œ ë°ì´í„°í¬ì¸íŠ¸ì— 50,000íšŒ ë¶€íŠ¸ìŠ¤íŠ¸ë© ì‹¤í–‰ ì¤‘...")
        
        results = {
            "reward_ate": bootstrap_ate(T, np.array(rewards), n_bootstrap=50000),
            "cooperation_ate": bootstrap_ate(T, np.array(coops), n_bootstrap=50000),
        }
        
        # ê²°ê³¼ ì €ì¥
        output_file = os.path.join(OUTPUT_DIR, "bootstrap_ci_existing_data.json")
        with open(output_file, "w") as f:
            json.dump(results, f, indent=2, ensure_ascii=False)
        
        elapsed = time.time() - start
        log.info(f"  âœ… Bootstrap CI ì™„ë£Œ ({elapsed:.0f}ì´ˆ)")
        log.info(f"    Reward ATE: {results['reward_ate']['ate_mean']:.6f} "
                f"CI: [{results['reward_ate']['ci_lower']:.6f}, {results['reward_ate']['ci_upper']:.6f}]")
        log.info(f"    Coop ATE: {results['cooperation_ate']['ate_mean']:.6f} "
                f"CI: [{results['cooperation_ate']['ci_lower']:.6f}, {results['cooperation_ate']['ci_upper']:.6f}]")
        
        return results
        
    except Exception as e:
        elapsed = time.time() - start
        log.error(f"  âŒ Bootstrap CI ì‹¤íŒ¨: {e} ({elapsed:.0f}ì´ˆ)")
        traceback.print_exc()
        return {"error": str(e)}


def task_paper_figures():
    """ë…¼ë¬¸ Figure ì¼ê´„ ìƒì„± (CPU + ë””ìŠ¤í¬ ì§‘ì•½ì )."""
    log.info("ğŸ–¼ï¸ [BONUS] ë…¼ë¬¸ Figure ì¼ê´„ ìƒì„± ì‹œì‘...")
    start = time.time()
    
    try:
        from simulation.jax.analysis.paper_figures import main as figures_main
        figures_main()
        elapsed = time.time() - start
        log.info(f"  âœ… Figure ìƒì„± ì™„ë£Œ ({elapsed:.0f}ì´ˆ)")
        return {"status": "completed", "elapsed": elapsed}
    except Exception as e:
        elapsed = time.time() - start
        log.error(f"  âŒ Figure ìƒì„± ì‹¤íŒ¨: {e} ({elapsed:.0f}ì´ˆ)")
        return {"error": str(e)}


def main():
    """CPU/ë©”ëª¨ë¦¬ ì§‘ì•½ì  ë¶„ì„ ìˆœì°¨ ì‹¤í–‰."""
    start_time = datetime.now()
    
    log.info("=" * 60)
    log.info("EthicaAI â€” CPU/ë©”ëª¨ë¦¬ ì§‘ì•½ì  ë¶„ì„ ì‹œì‘")
    log.info(f"ì‹œì‘ ì‹œê°: {start_time.strftime('%Y-%m-%d %H:%M:%S')}")
    log.info(f"CPU ì½”ì–´: {mp.cpu_count()}")
    log.info(f"JAX í”Œë«í¼: CPU (GPUëŠ” Full Sweepì— ì‚¬ìš© ì¤‘)")
    log.info(f"ì¶œë ¥ ë””ë ‰í† ë¦¬: {OUTPUT_DIR}")
    log.info("=" * 60)
    
    all_results = {}
    
    # ìˆœì°¨ ì‹¤í–‰ (ë©”ëª¨ë¦¬ ì¶©ëŒ ë°©ì§€)
    tasks = [
        ("bootstrap_ci", task_bootstrap_on_existing_data),
        ("lmm_causal_forest", task_lmm_causal_forest),
        ("sensitivity", task_sensitivity_analysis),
        ("lyapunov", task_lyapunov_analysis),
        ("convergence", task_convergence_proof),
        ("scale_comparison", task_scale_analysis),
        ("paper_figures", task_paper_figures),
    ]
    
    for task_name, task_fn in tasks:
        log.info(f"\n{'='*40}")
        log.info(f"ì‘ì—…: {task_name}")
        log.info(f"{'='*40}")
        
        try:
            result = task_fn()
            all_results[task_name] = result
            
            # ì¤‘ê°„ ì €ì¥
            task_file = os.path.join(OUTPUT_DIR, f"{task_name}.json")
            with open(task_file, "w", encoding="utf-8") as f:
                json.dump(result, f, indent=2, ensure_ascii=False, default=str)
            log.info(f"ğŸ’¾ ì €ì¥: {task_file}")
            
        except Exception as e:
            log.error(f"âŒ {task_name} ì „ì²´ ì‹¤íŒ¨: {e}")
            all_results[task_name] = {"error": str(e)}
    
    # ì „ì²´ ìš”ì•½ ì €ì¥
    end_time = datetime.now()
    summary = {
        "start_time": start_time.isoformat(),
        "end_time": end_time.isoformat(),
        "total_elapsed": str(end_time - start_time),
        "results": all_results,
    }
    
    summary_file = os.path.join(OUTPUT_DIR, "cpu_analysis_summary.json")
    with open(summary_file, "w", encoding="utf-8") as f:
        json.dump(summary, f, indent=2, ensure_ascii=False, default=str)
    
    log.info("\n" + "=" * 60)
    log.info("ğŸ CPU ë¶„ì„ ì™„ë£Œ!")
    log.info(f"ì†Œìš”: {end_time - start_time}")
    log.info(f"ê²°ê³¼: {summary_file}")
    log.info("=" * 60)


if __name__ == "__main__":
    main()
